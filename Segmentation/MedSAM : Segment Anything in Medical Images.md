# Segment Anything in Medical Images

### 1. 핵심 주장 및 주요 기여 요약[1]

**MedSAM(Medical Segment Anything Model)**은 의료영상 분야에 첫 번째 파운데이션 모델로, 다양한 의료영상 모달리티와 질환을 아우르는 **범용 의료영상 분할(universal medical image segmentation)**을 실현하기 위해 개발되었습니다. 본 논문의 핵심 기여는 다음과 같습니다:[1]

**주요 기여:**

- **대규모 의료영상 데이터셋 구축**: 1,570,263개의 이미지-마스크 쌍으로 구성되며, 10가지 이미징 모달리티와 30개 이상의 암 종류를 포괄[1]

- **범용 모델의 우월성 입증**: 86개의 내부 검증 작업과 60개의 외부 검증 작업에서 기존의 최첨단 파운데이션 모델(SAM)과 모달리티별 전문가 모델(U-Net, DeepLabV3)을 능가[1]

- **일반화 능력의 혁신**: 훈련에서 본 적 없는 새로운 데이터셋, 새로운 모달리티, 새로운 분할 대상에 대해서도 뛰어난 성능 유지[1]

- **임상 효율성 개선**: 수동 주석 작업 시간을 82% 이상 단축[1]

***

### 2. 해결 문제 및 제안 방법

#### 2.1 핵심 문제 정의[1]

기존 의료영상 분할 모델들의 주요 제약 사항:

1. **작업 특이성(Task-specificity)**: 특정 질병이나 모달리티만을 위해 설계되어 새로운 작업에 적용 시 성능 급감
2. **약한 경계(Weak boundary)**: 저명도 의료영상에서 경계가 불명확한 구조 분할의 어려움
3. **모달리티 다양성**: CT(3D), MRI(3D), X-Ray(2D), 초음파(2D) 등 다양한 데이터 형태에 대한 통합 처리 불가

#### 2.2 제안된 방법론

**MedSAM의 구조:**

MedSAM은 세 가지 주요 컴포넌트로 구성됩니다:[1]

1. **이미지 인코더(Image Encoder)**
   - Vision Transformer(ViT) 기반으로, 입력 이미지를 고차원 임베딩 공간으로 매핑
   - ViT-Base 사용 (12개 트랜스포머 레이어)
   - 입력 크기: 1024×1024×3 → 64×64 특성맵 (16배 다운스케일)

2. **프롬프트 인코더(Prompt Encoder)**
   - 경계 박스 프롬프트를 256차원 벡터 임베딩으로 변환
   - 위 왼쪽 점과 오른쪽 아래 점의 좌표를 임베딩

3. **마스크 디코더(Mask Decoder)**
   - 2개의 트랜스포머 레이어와 2개의 전치 합성곱층(transposed convolutional layers)으로 구성
   - 이미지 임베딩과 프롬프트 특성을 **교차주의(cross-attention)**로 융합

#### 2.3 손실 함수[1]

최종 손실 함수는 바이너리 교차 엔트로피 손실과 Dice 손실의 비가중 합입니다:

$$L_{BCE} = -\frac{1}{N}\sum_{i=1}^{N}[g_i \log(s_i) + (1-g_i)\log(1-s_i)]$$

$$L_{Dice} = 1 - \frac{2\sum_{i=1}^{N}g_i s_i}{\sum_{i=1}^{N}g_i^2 + \sum_{i=1}^{N}s_i^2}$$

$$L = L_{BCE} + L_{Dice}$$

여기서 $S, G$는 각각 분할 결과와 정답 마스크를 나타내고, $s_i, g_i$는 복셀 $i$의 예측값과 정답값입니다.[1]

#### 2.4 훈련 설정[1]

- **모델 초기화**: 사전훈련된 SAM(ViT-Base) 체크포인트에서 초기화
- **학습 파라미터**: 이미지 인코더(89,670,912개)와 마스크 디코더(4,058,340개)만 업데이트
- **최적화**: AdamW 옵티마이저 (β₁=0.9, β₂=0.999)
- **학습률**: 초기 1e-4, 가중 감쇠 0.01
- **배치 크기**: 160
- **에포크**: 150에포크, 마지막 체크포인트 선택
- **연산 환경**: 20개의 A100 80GB GPU

***

### 3. 모델 구조 상세 설명

#### 3.1 Transformer 기반 아키텍처[1]

MedSAM은 트랜스포머 아키텍처 기반으로 자연언어 처리와 이미지 인식에서의 성공을 의료영상 도메인으로 확장합니다.

**Vision Transformer (ViT) 인코더:**
- 입력 이미지를 16×16×3 크기의 2D 패치로 분할
- 1024×1024 이미지 → 64×64 패치 시퀀스 (3,072개 토큰)
- 각 블록: Multi-head Self-Attention + MLP
- Layer Normalization 포함

**프롬프트 인코더의 위치 인코딩:**
경계 박스의 좌표는 푸리에 특성(Fourier features)을 활용한 위치 인코딩으로 256차원 벡터로 변환됩니다.

**마스크 디코더의 교차주의(Cross-Attention):**
이미지 임베딩과 프롬프트 특성 사이의 교차주의 연산으로 두 정보를 효과적으로 융합합니다.

#### 3.2 데이터 전처리[1]

**강도 정규화 전략:**
- **CT 이미지**: Hounsfield 단위를 이용한 정규화
  - 연부 조직: W400, L40
  - 폐: W1500, L-160
  - 뇌: W80, L40
  - 최종 범위: 0-255로 재스케일

- **MR/X-Ray/초음파/유방촬영/OCT**: 0.5th-99.5th 백분위수로 클리핑 후 0-255로 재스케일
- **RGB 이미지** (내시경, 피부과, 안저, 병리): Max-Min 정규화

**모든 이미지 통일:**
- 최종 크기: 1024×1024×3
- 쌍입방 보간(bicubic interpolation) 사용
- 마스크는 최근접 보간(nearest-neighbor)으로 정확한 경계 유지

***

### 4. 성능 향상 분석

#### 4.1 내부 검증 결과 (86개 작업)[1]

| 모델 | 평균 Dice DSC | 성능 순위 빈도 |
|------|-------------|----------|
| **MedSAM** | 최고 (좁은 분포) | 1위: 최대빈도 |
| U-Net | 중간 | 2위: 높음 |
| DeepLabV3 | 중간 | 3위: 빈번 |
| SAM | 최저 | 마지막: 대부분 |

**특이 사항**: SAM은 명확한 경계의 RGB 이미지(예: 내시경 용종분할, DSC 91.3%)에서만 우수한 성능을 보임[1]

#### 4.2 외부 검증 결과 (60개 미이전 작업)[1]

- **인시경험 효과**: 전문가 모델들(U-Net, DeepLabV3)은 새로운 데이터셋에서 성능 저하
- **MedSAM 우월성**: 
  - 인시경험 작업에서도 일관되게 1위
  - 인시경(nasopharynx) 분할: DSC 87.8% (SAM 대비 52.3% 향상)
  - 미이전 모달리티에서도 뛰어난 성능 (최대 10% 향상)

#### 4.3 데이터셋 크기의 영향[1]

스케일링 법칙 검증:
- **10K 이미지**: 기본 성능
- **100K 이미지**: 성능 향상
- **1.57M 이미지** (전체): 최적 성능 달성

대규모 데이터셋이 모델 성능의 핵심 요소임을 입증[1]

#### 4.4 평가 지표[1]

**Dice Similarity Coefficient (DSC):**
$$DSC(G, S) = \frac{2|G \cap S|}{|G| + |S|}$$

**Normalized Surface Distance (NSD):**
$$NSD(G, S) = \frac{|B_G \setminus B_S| + |B_S \setminus B_G|}{|B_G| + |B_S|}$$

여기서 $B_G$와 $B_S$는 각각 전문가 주석과 분할 결과의 경계 영역입니다 (허용 오차 τ = 2mm)[1]

***

### 5. 일반화 성능과 제약 사항

#### 5.1 일반화 성능 향상 가능성[1]

**강점:**
1. **도메인 적응성**: 훈련 중 미이전 모달리티(다중 골수종 혈장세포)에 대해서도 우수한 성능
2. **작업 다양성**: 86개 내부 작업 + 60개 외부 작업에서 모두 최고 성능 유지
3. **미세 구조 처리**: 약한 경계의 구조도 정확하게 분할 (예: 자궁경부암, MR 이미지)
4. **구조적 유사성 학습**: 1.57M 이미지로부터 풍부한 의료 특성 학습

**일반화 향상 메커니즘:**
- 초기 SAM 모델의 강력한 기초 위에서 의료영상 특화 미세조정
- 광범위한 모달리티와 해부학적 구조로 모델 학습 범위 극대화

#### 5.2 주요 제약 사항[1]

1. **모달리티 불균형**
   - CT, MRI, 내시경 이미지가 대다수
   - 유방촬영 같은 소수 모달리티 성능 하락 가능성

2. **혈관 구조 분할의 어려움**
   - 경계박스 프롬프트의 모호성 (예: 안저 이미지의 동맥과 정맥)
   - 분기 구조(branching structure) 처리의 한계

3. **프롬프트 의존성**
   - 사용자 제공 경계박스에 민감
   - 부정확한 프롬프트 (너무 작거나 큼)로 인한 분할 오류

**한계 극복 전략:**
MedSAM은 풍부한 의료영상 특성을 학습했으므로, 미표현 모달리티나 복잡한 구조에 대해 **미세조정으로 효과적 분할 가능**[1]

***

### 6. 미래 연구에 미치는 영향 및 고려 사항

#### 6.1 패러다임 전환의 의의[2][3]

MedSAM은 의료영상 분야의 연구 방향을 근본적으로 변화시키고 있습니다:

**기존 패러다임**: 작업별 특화 모델 개발 (수천 개의 모델 필요)
**새로운 패러다임**: 통합 파운데이션 모델로 다양한 작업 해결

최근 연구들(2024-2025)은 이를 확장하고 있습니다:
- **MedCLIP-SAMv2**: 텍스트 기반 프롬프트 지원으로 범용성 강화[2]
- **VISTA3D**: 2D 파운데이션 모델을 3D 의료영상으로 확장[4]
- **SemiSAM+**: 제한된 라벨 데이터에서의 준지도학습 프레임워크[5]

#### 6.2 임상 응용 가능성[6][1]

1. **종양 분할 가속화**: 3D 종양 자동 주석과 부피 계산으로 치료 반응 평가 고속화
2. **검사 효율 향상**: 주석 시간 82% 단축으로 임상 워크플로우 개선
3. **의료 도구 개발 촉진**: 새로운 진단 및 치료 도구 개발 기반 제공

#### 6.3 향후 연구 시 고려할 점

**1. 3D 의료영상 처리 확장**[4]
- 현재 MedSAM은 2D 슬라이스 기반 처리
- VISTA3D의 등장으로 3D 전체 볼륨 처리의 중요성 증대
- 슬라이스 간 공간 정보 활용 필요

**2. 부정확한 프롬프트 처리**[7]
- 자동 프롬프트 생성 기술 개발 (FA-SAM 같은 접근)
- 사용자 오류에 강건한 모델 구축

**3. 모달리티 불균형 해결**[8][9]
- 소수 모달리티(유방촬영, OCT 등)에 대한 성능 개선
- 균형잡힌 데이터셋 구성 및 샘플링 전략

**4. 저화질 이미지와 복잡한 구조**[8]
- 저명도, 잡음이 많은 영상 처리 개선
- 혈관 같은 미세 분기 구조의 정확한 분할

**5. 도메인 일반화 강화**[10][7]
- 단일 소스 도메인 일반화(SSDG) 기법 적용
- 도메인 외 다양성에 대한 로버스트성 강화

**6. 생물학적 영상 확장**[1]
- 세포 현미경 이미지 분할
- 전자 현미경 소기관 분할
- 기초 과학 영역으로의 적용

**7. 라벨링 효율성 개선**[11][5]
- 준지도학습 프레임워크 개발
- 적응형 라벨링 전략 구현
- 검색 기반 적응(retrieval-augmented) 방식 활용

**8. 임상 검증 및 규제 승인**[6]
- 실제 임상환경에서의 다기관 검증 연구
- FDA 승인 같은 규제 요구사항 충족
- 임상 통합 워크플로우 개발

#### 6.4 최신 연구 동향 (2024-2025)[3][12][9][5][2][4]

최근 의료영상 분할 분야의 중요한 발전 방향:

**기초 모델의 다원화**:
- 텍스트 프롬프트 기반 범용 분할 모델
- 자동 분할과 상호작용형 분할의 통합
- 3D 전용 파운데이션 모델 등장

**준지도 및 적응형 학습**:
- 제한된 라벨 데이터로의 효율적 적응
- 도메인 외 일반화 기법 개발
- 잡음 강건성 향상

**엣지 디바이스 배포**:
- 경량 모델 설계로 CPU/노트북 기반 실행 가능성
- 의료 현장의 GPU 제약 극복

***

## 결론

**MedSAM**은 의료영상 분할 분야의 획기적인 연구로, **파운데이션 모델을 통한 범용 의료영상 분할**의 가능성을 실증했습니다. 1.57M 이미지의 대규모 학습과 뛰어난 일반화 능력으로 작업 특이성의 한계를 극복하고, 86개 내부 및 60개 외부 검증 작업에서 일관되게 최고 성능을 달성했습니다.[13][1]

향후 연구는 **3D 의료영상 처리**, **모달리티 불균형 해결**, **자동 프롬프트 생성**, **임상 통합**에 집중될 것으로 예상되며, 이러한 진화는 궁극적으로 **개인맞춤형 치료 계획 수립**과 **의료 진단 도구의 고도화**를 실현할 것입니다.[9][6][1]

[1](https://ppl-ai-file-upload.s3.amazonaws.com/web/direct-files/attachments/65988149/5690d25d-3066-4989-881f-7ca495635b6a/2304.12306v3.pdf)
[2](https://arxiv.org/pdf/2409.19483.pdf)
[3](https://arxiv.org/pdf/2312.17183.pdf)
[4](https://openaccess.thecvf.com/content/CVPR2025/papers/He_VISTA3D_A_Unified_Segmentation_Foundation_Model_For_3D_Medical_Imaging_CVPR_2025_paper.pdf)
[5](https://arxiv.org/html/2502.20749)
[6](http://arxiv.org/pdf/2411.02745.pdf)
[7](https://arxiv.org/html/2507.17281v1)
[8](https://pmc.ncbi.nlm.nih.gov/articles/PMC12115501/)
[9](https://pubmed.ncbi.nlm.nih.gov/40606341/)
[10](https://papers.miccai.org/miccai-2025/paper/1075_paper.pdf)
[11](https://arxiv.org/abs/2408.08813)
[12](https://arxiv.org/abs/2505.09274)
[13](https://www.nature.com/articles/s41467-024-44824-z)
[14](https://arxiv.org/pdf/2304.12306.pdf)
[15](https://arxiv.org/pdf/2306.02416.pdf)
[16](https://arxiv.org/pdf/2305.03678.pdf)
[17](http://arxiv.org/pdf/2410.22223.pdf)
[18](https://openaccess.thecvf.com/content/ICCV2023/papers/Butoi_UniverSeg_Universal_Medical_Image_Segmentation_ICCV_2023_paper.pdf)
[19](https://books.google.com/books/about/Medical_Image_Segmentation_Foundation_Mo.html?id=j75HEQAAQBAJ)
