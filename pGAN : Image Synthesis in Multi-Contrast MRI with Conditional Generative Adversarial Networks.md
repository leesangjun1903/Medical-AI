# pGAN : Image Synthesis in Multi-Contrast MRI with Conditional Generative Adversarial Networks | Image generation

## 1. 핵심 주장 및 주요 기여  
본 논문은 멀티-콘트라스트 MRI에서 결손 또는 노이즈로 손상된 대비(contrast)를 다른 대비들로부터 합성하는 **조건부 생성적 적대 신경망(cGAN)** 기반의 새로운 방법을 제안한다. 주요 기여는 다음과 같다:  
- **고주파수 정보 보존**: 기존 회귀 기반 또는 평균 제곱 오차 손실만 사용한 방법들이 고주파수 디테일을 잃는 한계를, 적대적 손실(adversarial loss)을 도입하여 극복.  
- **등록(paired)·비등록(unpaired) 상황 모두 지원**:  
  - 등록된 데이터에는 픽셀 단위 손실(pixel-wise L₁ loss)과 적대적 손실을 결합한 **pGAN**.  
  - 비등록 데이터에는 순환 일관성 손실(cycle-consistency loss)과 적대적 손실을 결합한 **cGAN**.  
- **이웃 단면 정보 활용**: 인접 단면(3개)을 입력으로 사용해 구조적 상관관계를 반영, 합성 정확도 향상.  

## 2. 해결 문제 및 제안 방법  

### 문제 정의  
- **목표**: 소스 대비 이미지 $$x$$로부터 타깃 대비 이미지 $$y$$를 합성.  
- **과제**: 제한된 스캔 시간이나 장비 고장 등으로 인해 일부 대비가 결손·손상될 때 진단 정보를 복원.

### 모델 구조 및 손실 함수  
1. **pGAN (paired GAN)**  
   - 입력: 등록된 $$(x,y)$$ 페어  
   - 네트워크: 생성자 $$G$$와 판별자 $$D$$  
   - 손실:
   
  $$
       \mathcal{L}\_{cGAN}(G,D)
       = \mathbb{E}\_{x,y}[\log\ D(x,y)] + \mathbb{E}\_{x}[\log(1 - D(x, G(x)))]
  $$
      
  $$
       \mathcal{L}\_{L1}(G)
       = \mathbb{E}\_{x,y}[\|y - G(x)\|_{1}]
  $$
     
  $$
       \mathcal{L}\_{pGAN} = \mathcal{L}\_{cGAN} + \lambda\,\mathcal{L}_{L1}
  $$  

2. **cGAN (cycle-consistency GAN)**  
   - 입력: 비등록(unpaired) $$\{x_i\}, \{y_j\}$$  
   - 네트워크: 두 쌍의 생성자 $$G: X\to Y,\ F: Y\to X$$ 및 판별자 $$D_X,D_Y$$  
   - 손실:  
     - 적대적 손실 (LSGAN식)
      
  $$\mathcal{L}_{GAN}(G,D_Y)$$ 및 $$\mathcal{L}\_{GAN}(F,D_X)$$  

   - 순환 일관성 
     
  $$\mathcal{L}_{cyc}(G,F) = \mathbb{E}_x[\|F(G(x)) - x\|_1] + \mathbb{E}_y[\|G(F(y)) - y\|_1]$$  
  
  $$
    \mathcal{L}\_{cGAN} = \mathcal{L}\_{GAN}(G,D_Y) + \mathcal{L}\_{GAN}(F,D_X) + \lambda\,\mathcal{L}_{cyc}
  $$

3. **이웃 단면 모델**  
   - 단일 단면 대신 **연속 3개 단면**을 입력으로 사용하여 모양적 상관관계 반영.  
   - pGAN·cGAN 모두에 적용 시 PSNR 및 SSIM 향상 관측.

## 3. 성능 향상 및 한계  

| 데이터셋 | 비교 대상      | 평균 PSNR 향상 (pGAN vs 최우수 경쟁) |
|----------|---------------|-----------------------------------|
| MIDAS    | cGANᵣₑg       | +2.72 dB (T2), +0.55 dB (T1)      |
| IXI      | Multimodal    | +1.04 dB (T2), +2.41 dB (T1)      |
| BRATS    | Multimodal    | +2.34 dB (T2), +2.27 dB (T1)      |

- **정성적 우위**: 경계부 및 고주파수 조직 구조 재현력 우수.  
- **한계**:  
  - 등록된 참조 이미지에 의존할 때 여전히 보정 필요.  
  - 다중 대비 소스 입력 일반화는 미탐구.  
  - 심층 네트워크 학습 위해 대규모 데이터 필요.

## 4. 일반화 성능 향상 가능성  
- **비등록 학습(cGAN)**: 페어링되지 않은 대규모 스캔 데이터 활용 가능 → 다양한 환자·장비 환경에 강인.  
- **다중 대비 입력 확장**: 여러 대비 이미지 동시 입력으로 **멀티모달 합성** 구현 시, 특정 대비 결손 시에도 안정적 합성 기대.  
- **혼합 데이터 학습**: 페어 및 언페어 데이터 혼합 사용 시 전반적 일반화 성능 추가 개선.

## 5. 향후 연구 영향 및 고려 사항  
- **임상 응용**: 스캔 시간이 제약된 응급·소아 검사에서 미획득 대비 보완.  
- **멀티모달 확대**: CT, PET 등 이종 영상 간 합성으로 영상 융합 연구 촉진.  
- **데이터 효율성**: 적은 레이블 데이터로도 고성능 달성 가능한 준지도·자기 지도 학습 기법 도입 검토.  
- **안정성·윤리성**: 합성 영상의 진단 오류 가능성 평가 및 안전성 가이드라인 마련 필요.

[1] https://ppl-ai-file-upload.s3.amazonaws.com/web/direct-files/attachments/22370781/289c32f3-c260-40b3-af78-4ae91cbb2c99/1802.01221v1.pdf
