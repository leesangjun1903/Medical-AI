# Unconditional Latent Diffusion Models Memorize Patient Imaging Data: Implications for Openly Sharing Synthetic Data | Image generation, Memorization

# 핵심 요약

**주장 및 기여**  
1. **훈련 데이터 메모리제이션 문제 제기**  
   - Unconditional Latent Diffusion Models(LDMs)가 의료 영상 데이터의 개별 환자 정보를 과도하게 암기하여, 합성 데이터 생성 시 실제 환자 영상과 거의 동일한 복제본을 생산함으로써 개인 식별 위험을 초래할 수 있음을 입증.  
2. **복제본(메모리제이션) 탐지 프레임워크 제안**  
   - 저차원 임베딩 공간에서 자기 지도 학습을 이용한 콘트라스티브 학습 기법을 통해, 합성된 영상과 훈련 데이터 사이의 유사도를 계산하고, 일정 임계값(95번째 백분위) 이상인 경우 복제본으로 간주하는 효율적·견고한 탐지 파이프라인 설계.  
3. **다양한 요인 분석 및 완화 전략 제시**  
   - 모델 과훈련(over-training)이 메모리제이션을 심화시키는 반면, 데이터 증강(회전·뒤집기)∙훈련 데이터 규모 확대∙작은 모델 구조 사용이 복제본 생성 비율을 감소시킴을 실험적으로 입증.  

# 문제 정의 및 제안 기법

## 해결하고자 하는 문제  
- 의료 영상 분야에서 LDM 기반 합성 데이터가 환자 프라이버시를 보장한다는 전제를 뒤집고, 실제 환자 영상이 합성물로 그대로 재생산되어 재식별 위험을 높이는 **메모리제이션 문제**를 다룸.

## 제안 방법  
1. **자기 지도 콘트라스티브 학습(Contrastive Learning)**  
   - 훈련 영상과 그 변형(회전·뒤집기)을 *양의 쌍*(positive pair)으로, 다른 영상과는 *음의 쌍*(negative pair)으로 학습.  
   - Normalized Temperature-scaled Cross Entropy (NT-Xent) 손실:  

$$
     L_i = -\log\frac{\exp(\mathrm{sim}(e_i,e_i')/\tau)}{\sum_{j\neq i}\exp(\mathrm{sim}(e_i,e_j)/\tau) + \sum_{j\neq i'}\exp(\mathrm{sim}(e_i',e_j)/\tau)}
     $$  
     
  여기서 $$e_i, e_i'$$는 양의 샘플 임베딩, $$\tau$$는 온도 파라미터.  
2. **복제본 탐지 파이프라인**  
   - 훈련/검증/합성 데이터 전체를 상기 임베딩 모델로 투영.  
   - 훈련-검증 임베딩 유사도 분포의 95번째 백분위($$\tau$$)를 복제본 임계값으로 설정.  
   - 각 훈련 샘플별로 가장 유사한 합성 샘플의 피어슨 상관계수가 $$\tau$$ 이상인 경우 ‘메모리제이션된 샘플’로 분류.  

## 모델 구조  
- **Latent Diffusion Models**  
  - 2D/3D VAE 또는 VQ-GAN 기반 인코더-디코더로 고차원 영상→잠재 공간($$z$$) 압축  
  - 잠재 공간에서 노이즈 추가(forward)→점진적 복원(reverse denoising)으로 샘플 생성  
- **비교 대상**: CCE-GAN, Proj-GAN, VQVAE-Transformer 등

# 성능 향상 및 한계

## 성능 및 발견  
- 3D LDM: 훈련 데이터의 평균 37.2%가 메모리제이션, 합성 샘플의 평균 68.7%가 복제본으로 탐지.  
- 비확산 모델 대비 LDM이 더 높은 합성 품질과 더 높은 메모리제이션 취약성 동시 보유.  
- 복제본 탐지 민감도 80–100%, 특이도 85–95%로 실험적 검증.

## 일반화 성능 관련 분석  
- **데이터 증강**: 훈련 시 회전·뒤집기 적용시 메모리제이션 50% 이상 감소, 합성 품질 유지.  
- **훈련 규모**: 데이터 양 증가 시 개별 샘플 반복 학습 횟수 감소로 메모리제이션 비율 완화.  
- **모델 크기**: 소형 모델은 대형 모델 대비 덜 암기하나, 지나치게 작은 모델은 학습 데이터 소수일 때도 암기 발생.

## 한계  
- **의료 영상 특성**: 희귀·특이 사례일수록 암기 위험 증대 가능성, 향후 예상치 못한 사례 일반화 불확실.  
- **임계값 의존성**: 95번째 백분위 사용했으나, 특정 응용에 따라 민감도·특이도 조절 필요.  
- **대규모 합성셋**: 합성 샘플 수 증가 시 위양성(False Positive) 증가하는 경향.

# 향후 연구 방향 및 고려 사항

- **메모리제이션 인식 학습**: 훈련 손실에 암기 억제 항목 추가하거나 조기 종료(Early stopping) 기준 개발.  
- **조건부·다중모달 확장**: 텍스트-영상, 시간적 연속성(비디오) 등 복합 데이터로 일반화 보장 방법 연구.  
- **차등 개인정보 보호(DP) 기법 결합**: Differentially private diffusion models 도입으로 이론적 재식별 위험 보장.  
- **희귀 사례 보강**: 희귀·비정형 샘플에 대한 오버샘플링 및 메모리제이션 특성 분석 강화.  
- **실제 배포 가이드라인**: 합성 데이터 공유 전 검증 파이프라인 표준화 및 인증 절차 마련.

[1] https://ppl-ai-file-upload.s3.amazonaws.com/web/direct-files/attachments/22370781/9af2bdfb-543b-447e-9fc9-b61af388ac0e/2402.01054v3.pdf
