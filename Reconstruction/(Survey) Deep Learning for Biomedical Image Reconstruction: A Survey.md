# Deep Learning for Biomedical Image Reconstruction: A Survey

**핵심 주장 및 주요 기여**  
“Deep Learning for Biomedical Image Reconstruction: A Survey”는 전통적 이미지 재구성 기법(해석적·최적화 기반)들의 한계를 짚고, 딥러닝(DL) 기법이 이들 문제를 어떻게 극복하며 재구성 품질과 속도를 획기적으로 개선하는지 정리한 종합 리뷰이다.  
- **주장**: DL 기반 방법은 자동 특징 추출과 실시간 추론을 통해 노이즈 및 불완전 데이터에서 전통 기법이 직면한 노이즈 민감성·계산 비용 문제를 완화할 수 있다.  
- **기여**:  
  1. 전통적 해석적·반복적 재구성 알고리즘의 한계 분석  
  2. DL을 후처리·전처리·엔드투엔드·태스크 통합 관점으로 분류·정리  
  3. 각 패러다임별 수식화(예: (2), (3)), 구조(Unrolled-Net, U-Net, GAN 등) 비교  
  4. 데이터셋·평가 지표(SSIM, PSNR 등)·추론 속도 분석  
  5. 도전 과제(일반화·해석 가능성·로버스트니스)와 미래 연구 방향 제안  

***

## 1. 해결하고자 하는 문제  
- **역문제의 불안정성(ill-posedness)**: 측정값 y에 대응되는 해 x가 다수이며 잡음·서브샘플링시 해결 공간이 극히 넓어짐  
- **전통 기법의 단점**  
  - 해석적 방법(FBP, IFT): 완전·무잡음 데이터에서만 우수, 불완전·저용량·저선량 데이터에 취약  
  - 반복적 방법(Optimization with regularization): 잡음·불완전성에 강하나 매번 수백∼수천번 투영·역투영으로 계산 비용이 매우 높고 하이퍼파라미터 의존  

***

## 2. 제안하는 DL 기반 접근법  

### 2.1 Two-Step 처리 모델  
  1) **전처리(DL→Analytic)**  
     - 센서 도메인에서 결손 신호 복원 후 해석적 변환 수행  
     - 수식: y_incomplete → f_θ(y) ≈ y_full → A⁻¹(f_θ(y))  
     - 예: U-Net k-space 보정 + IFT  
  2) **후처리(Analytic→DL)**  
     - 초기 재구성 이미지 I₀ → DL 모델 g_ϕ(I₀)로 정제  
     - 수식(2-step): $$\hat x = g_ϕ(A^{-1}(y))$$  

### 2.2 End-to-End 직접 추정  
  - **Generic CNN**: U-Net, ResNet, GAN을 이용해 y→x 매핑 $$x=F_θ(y)$$  
    - 최적화: $$\min_θ L(F_θ(y),x_{GT}) + λR(F_θ(y))$$  
  - **Optimization Unrolling**: ADMM-Net, PD-Net 등 반복 알고리즘을 신경망 층으로 풀어 각 단계 파라미터를 학습  
    - 수식 예(ADMM-Net): iteration k마다  

$$
      \begin{aligned}
      z^{k+1}&=\mathrm{prox}_{\rho R}(x^k + u^k)\\
      x^{k+1}&=\arg\min_x \|A(x)-y\|^2 + \tfrac{\rho}{2}\|x-z^{k+1}+u^k\|^2\\
      u^{k+1}&=u^k + x^{k+1}-z^{k+1}
      \end{aligned}
      \quad\longrightarrow\quad\text{learnable layer로 대체}
      $$
  
  - **Raw-to-Task**: 재구성과 진단(분할·검출)을 단일 네트워크로 학습하여 전체 목적함수 최적화  

***

## 3. 모델 구조 및 성능 향상  
- **구조별 비교**  
  | 패러다임           | 대표 구조             | 주요 손실함수       | 성능 이득              |
  |-------------------|----------------------|---------------------|-------------------------|
  | Two-Step 전처리    | U-Net + IFT          | L2                  | 아티팩트 감소, 속도↑    |
  | Two-Step 후처리    | Autoencoder, GAN     | L1+Adversarial      | 세부 텍스처 보존↑       |
  | End-to-End Generic | U-Net, ResNet, GAN   | L2, perceptual, adversarial | 실시간 재구성, 전반적 화질↑ |
  | Unrolled-Iterative | ADMM-Net, PD-Net     | NMSE, L2            | 최적화 안정성↑, 해석가능성↑ |
  | Raw-to-Task        | Joint CNN           | Lrec + Ltask        | 진단 정확도↑            |

- **한계**  
  - **과적합·일반화 어려움**: 제한된 의료 데이터, 시뮬레이션 도메인 간 갭  
  - **해석 불투명성**: 블랙박스 특성으로 신뢰도·법적 검증 요구  
  - **로버스트니스**: 분포 변화·노이즈에 민감, 불안정 학습  
  - **연산 비용**: 추론은 빠르나 재학습 시 수일~수주 소요  

***

## 4. 일반화 성능 향상 관점  
- **도메인 적응(Transfer/Federated Learning)**:  
  - 시뮬레이션·임상 데이터 간 분포 차 보정(CycleGAN, MMD 등)  
  - 기밀성 유지를 위한 연합 학습  
- **물리 기반 시뮬레이션**:  
  - Forward 모델 정확도와 계산 비용 균형 조정  
  - 가상-실제 데이터 갭 최소화  
- **네트워크 경량화 & 정량화**:  
  - 구조 가지치기·양자화를 통한 모바일·엣지 배포  
- **데이터 증강**:  
  - 생체·장기별 특성 반영한 비대칭 시뮬레이션  

***

## 5. 향후 연구 영향 및 고려 사항  
- **다중 모달리티 융합 재구성**: CT/MRI, DOT/MRI 등 상호보완 정보 활용  
- **어텐션 기반 샘플링 학습**: 제한적 측정 조건에서 최적 스캔 경로 자동화  
- **태스크 중심 평가 지표 개발**: 진단·치료 관점의 임상적 유용성 측정  
- **자동 하이퍼파라미터 튜닝**: 메타러닝·베이지안 최적화 도입  
- **모델 해석 가능성 강화**: 물리적 제약 통합 및 설명 가능 AI 기법 접목  

위 논문은 **딥러닝 기반 재구성**의 현 상태와 패러다임을 체계적으로 정리함으로써, 향후 연구자들이 **일반화·로버스트·해석 가능**한 모델 개발에 집중하도록 이끄는 가이드라인 역할을 할 것이다.

[1] https://ppl-ai-file-upload.s3.amazonaws.com/web/direct-files/attachments/22370781/9987f90b-bbe3-416c-95d6-ee101b62e830/2002.12351v1.pdf

# 3장 딥러닝 기반 생의학 영상 재구성 이해하기

생의학 영상 재구성에서 딥러닝(Deep Learning, DL)이 해결하고자 하는 핵심 과제는 전통적 해석적·최적화 기반 방법이 갖는  
- 노이즈에 취약하고  
- 불완전 샘플링(저용량·저선량·제한 각도) 시 화질 저하  
- 반복적 최적화 방식의 높은 계산 비용  
를 극복하는 것입니다.  

딥러닝 기반 접근법은 크게 **세 가지 패러다임**으로 구분되어 연구되고 있습니다.  

---  

## 1. Two-Step 처리 모델  
기존 알고리즘과 DL을 결합하여 재구성 품질을 높이되 계산 속도를 확보합니다.  
  
1) **전처리(Pre-processing)**  
   - **목표**: 불완전한 센서 신호 $$y_{\text{incomplete}}$$를 DL 모델로 보완한 뒤 전통적 역변환(예: IFT, FBP)에 전달  
   - **수식화**:  

$$
       \tilde y = f_\theta\bigl(y_{\text{incomplete}}\bigr),\quad
       \hat x = A^{-1}\bigl(\tilde y\bigr)
     $$  

  - **예시**:  
     - k-space의 언샘플링 복원에 U-Net 사용 후 IFT  
     - CT 제한 각도 뷰 보완 후 FBP  

2) **후처리(Post-processing)**  
   - **목표**: 해석적·반복적 방법으로 얻은 초기 영상 $$x_0$$를 DL 모델로 깨끗하게 정제  
   - **수식화**:  

$$
       x_0 = A^{-1}(y),\quad
       \hat x = g_\phi(x_0)
     $$  
   
   - **예시**:  
     - FBP로 만든 CT 영상을 오토인코더/GAN으로 디노이징  
     - 스펙트럴 반복 알고리즘 결과를 U-Net으로 아티팩트 제거  

**장점**  
- 기존 장비·파이프라인을 크게 변경하지 않으면서 DL 특유의 특징 추출력 활용  
- 전통 기법 대비 계산 속도 단축  

**단점**  
- DL 처리 전후 단계가 분리되어 학습 목표가 모호  
- 초기 재구성 단계의 오류가 이후 DL 보정 한계를 결정  

---  

## 2. End-to-End 직접 추정  
센서 데이터 $$y$$에서 영상 $$x$$를 한 번에 예측하도록 네트워크를 학습합니다.  

### 2.1 Generic 모델  
- **구조**: U-Net, ResNet, GAN, Encoder–Decoder 등  
- **목표함수**:

$$
    \min_\theta L\bigl(F_\theta(y),\,x_{\mathrm{GT}}\bigr) + \lambda R\bigl(F_\theta(y)\bigr)
  $$  
  
  - $$L$$: MSE, SSIM 기반 손실 혹은 퍼셉추얼/어드버서리얼 손실 조합  
  - $$R$$: 과적합 방지를 위한 L1/L2 정규화 등  

- **특징**  
  - 완전 자동화된 파이프라인  
  - **수준 높은 추상 특징**을 다중 계층에서 학습  
  - 심층화된 네트워크 깊이에 따른 블랙박스 문제  

### 2.2 Iteration Unrolling  
전통적 최적화 알고리즘(예: ADMM, PDHG)을 네트워크 층으로 ‘풀어(unroll)’ 각 단계의 파라미터를 학습합니다.  

- **예: ADMM-Net**  
  - ADMM 반복의 계산 흐름을 각각 하나의 네트워크 모듈로 구현  
  - 학습 데이터로부터 각 단계의 페널티 파라미터·근사 연산자를 함께 최적화  

- **장점**  
  - 수학적 최적화 알고리즘의 **수렴 안정성**과 DL의 **표현력**을 결합  
  - 반복 수나 페널티 값을 학습 과정에서 자동 조정  

- **단점**  
  - 반복 단계가 많아 네트워크 구조가 복잡  
  - 메모리·연산량 요구  

---  

## 3. Raw-to-Task (재구성 + 진단 통합)  
재구성된 영상을 거쳐 진단(분할·검출)에 활용하기보다, 센서 데이터에서 곧바로 임상 과제(예: 병변 분할)에 적합한 결과를 예측합니다.  
- **구조**: 재구성과 분할 네트워크를 하나로 연결(하나의 손실함수로 공동 학습)  
- **이점**  
  - 재구성과 진단 단계 간 **특징 공유**로 전체 목적 최적화  
  - 전통 재구성에서 발생 가능한 불필요 화질 왜곡 최소화  

---  

## 요약  
1. **Two-Step**: 전처리 혹은 후처리로 DL 보완 → 기존 기법 활용  
2. **End-to-End**: 센서→영상 매핑 전 과정을 한 번에 학습  
   - Generic CNN vs. Iteration Unrolling  
3. **Raw-to-Task**: 재구성과 분석을 통합하여 진단·분할 성능 극대화  

이 세 가지 패러다임은 각각 **속도**, **품질**, **해석 가능성** 간의 균형점을 달리 두고 있으며, 연구자는 응용 분야·제약 조건에 맞추어 최적의 접근을 선택하거나 하이브리드 방식을 고안합니다.

[1] https://ppl-ai-file-upload.s3.amazonaws.com/web/direct-files/attachments/22370781/9987f90b-bbe3-416c-95d6-ee101b62e830/2002.12351v1.pdf
