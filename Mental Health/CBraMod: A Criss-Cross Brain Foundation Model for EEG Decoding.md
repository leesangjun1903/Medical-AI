# CBraMod: A Criss-Cross Brain Foundation Model for EEG Decoding

### 1. 핵심 주장과 주요 기여

**CBraMod**는 EEG 신호 디코딩을 위한 혁신적인 기초 모델(Foundation Model)로서, 기존 EEG 기초 모델의 두 가지 핵심 문제를 해결합니다. 첫째, 기존 방법들은 **완전 EEG 모델링 전략**을 사용하여 모든 EEG 패치 간의 공간적·시간적 의존성을 함께 모델링하지만, EEG 신호의 고유한 구조적 특성을 무시합니다. EEG 신호는 이미지와 달리 이질적인 공간 및 시간 의존성을 가지며, 동일 채널 또는 시간 간격 내 패치 간 의존성이 서로 다른 채널/시간 간격의 패치보다 강할 수 있습니다. 둘째, 다양한 형식의 EEG 데이터로 인해 기존 모델의 **일반화 성능이 제한**됩니다.[1]

이러한 문제를 해결하기 위해 CBraMod는 다음 세 가지 주요 기여를 제시합니다:[1]

- **Criss-Cross 트랜스포머**: 두 개의 병렬 주의 메커니즘(공간 주의와 시간 주의)을 통해 공간 및 시간 의존성을 **별도로 모델링**
- **비대칭 조건부 위치 인코딩(ACPE)**: 다양한 채널 구성과 시간 길이를 가진 EEG 데이터에 **적응 가능한 동적 위치 정보 인코딩**
- **광범위한 평가**: 10개의 다운스트림 BCI 작업과 12개의 공개 데이터셋에서 **최신 성능** 달성으로 강력한 일반화 능력 입증

***

### 2. 해결하고자 하는 문제와 제안된 방법

#### 2.1 문제 정의

EEG 기반 뇌-컴퓨터 인터페이스(BCI) 및 임상 응용의 발전이 제한되는 이유:

1. **데이터 부족**: EEG 수집 및 라벨 작성이 비용 및 시간 소모적
2. **신호 형식 다양성**: 채널 구성, 시간 길이, 샘플링 레이트가 데이터셋마다 다름
3. **구조적 특성 무시**: 기존 기초 모델들이 EEG의 이질적 공간-시간 특성을 무시

#### 2.2 제안된 방법론

**EEG 패칭 및 마스킹**[1]

EEG 샘플 $$S \in \mathbb{R}^{C \times T}$$를 고정 길이 시간 윈도우 $$t$$로 분할하여 패치 집합 $$X \in \mathbb{R}^{C \times n \times t}$$를 생성합니다:

$$n = \lfloor T/t \rfloor$$

여기서 $$C$$는 채널 수, $$T$$는 타임스탭 수, $$n$$은 각 채널 내 패치 수입니다.

마스킹은 베르누이 분포에서 비율 $$r$$로 무작위로 생성됩니다:[1]

$$\tilde{x}_{i,j} = \begin{cases} x_{i,j}, & m_{i,j} = 0 \\ x_M, & m_{i,j} = 1 \end{cases}$$

**시간-주파수 패치 인코딩**[1]

각 패치에서 시간 영역과 주파수 영역 특성을 동시에 추출합니다:

$$e_{i,j} = e^t_{i,j} + e^f_{i,j}$$

여기서 $$e^t_{i,j} \in \mathbb{R}^d$$는 시간 영역 임베딩, $$e^f_{i,j} \in \mathbb{R}^d$$는 고속 푸리에 변환(FFT)을 통한 주파수 영역 임베딩입니다.

**비대칭 조건부 위치 인코딩(ACPE)**[1]

ACPE는 조건부 위치 인코딩(CPE)을 수정하여 비대칭적으로 설계되었습니다. 2D 심화학 합성곱 계층으로 구성되며, 공간(채널) 차원에서는 **긴 범위** 위치 정보를, 시간 차원에서는 **단거리** 위치 정보를 인코딩합니다:[1]

$$E^o = E + E^p = \{e_{i,j} + e^p_{i,j} | i \in [1,2,...,C], j \in [1,2,...,n]\}$$

이는 EEG의 다양한 채널 형식(참조 방식: 귀, 평균, REST, 쌍극 등)에 **적응 가능**하게 합니다.[1]

**Criss-Cross 트랜스포머**[1]

핵심 혁신은 공간 주의(S-Attention)와 시간 주의(T-Attention)를 병렬로 실행하는 메커니즘입니다.

입력 임베딩 $$\tilde{E} \in \mathbb{R}^{C \times n \times d}$$를 $$n$$개의 공간 스트라이프로 분할합니다: $$\tilde{E} = [\tilde{E}_1, \tilde{E}_2, ..., \tilde{E}_n]$$, 여기서 각 $$\tilde{E}_j \in \mathbb{R}^{C \times d}$$입니다.

**공간 주의(S-Attention)**는 각 시간 간격 내에서 채널 간 의존성을 모델링합니다:[1]

$$F^j_k = \text{Attention}(\tilde{E}_j W^Q_k, \tilde{E}_j W^K_k, \tilde{E}_j W^V_k)$$

$$\text{S-Attention}_k(\tilde{E}) = [F^1_k, F^2_k, ..., F^n_k]$$

여기서 $$j \in [1,2,...,n]$$, $$W^Q_k, W^K_k, W^V_k \in \mathbb{R}^{d \times d_k}$$는 선형 투영 행렬입니다.

**시간 주의(T-Attention)**는 동일 채널 내 시간 패치 간 의존성을 캡처합니다.

8개 헤드의 중간 계층 임베딩을 분할하여 4개 헤드는 공간 주의로, 4개는 시간 주의로 처리합니다:[1]

$$\text{Criss-Cross-Attention}(\tilde{E}) = \text{Concat}(\text{head}_1, ..., \text{head}_K)$$

$$\text{head}_k = \begin{cases} \text{S-Attention}_k(\tilde{E}), & k \in [1,...,K/2] \\ \text{T-Attention}_k(\tilde{E}), & k \in [K/2+1,...,K] \end{cases}$$

**마스크된 EEG 재구성**[1]

자기 지도 학습을 위해 평균제곱오차(MSE) 손실로 마스크된 패치만 재구성합니다:[1]

$$L = \|\hat{X}_M - X_M\|^2$$

여기서 $$\hat{X}_M$$은 예측 마스크된 패치, $$X_M$$은 원본 마스크된 패치입니다.

***

### 3. 모델 구조 및 아키텍처

**전체 아키텍처 개요**:

1. **입력**: 원본 EEG 신호 $$S \in \mathbb{R}^{C \times T}$$

2. **패칭 및 마스킹**: 고정 시간 윈도우(1초 = 200 데이터 포인트)로 분할

3. **패치 인코딩**:
   - 시간 영역: 3개 층 1D 합성곱 + 그룹 정규화 + GELU
   - 주파수 영역: FFT + 완전 연결 계층
   - 결과 차원: $$d = 200$$

4. **비대칭 조건부 위치 인코딩**: 1층 2D 심화학 합성곱 (커널 크기: $$k_s > k_t$$)

5. **Criss-Cross 트랜스포머 블록** (총 12개):
   - 각 블록: 레이어 정규화 + Criss-Cross 주의 + 피드포워드
   - 숨겨진 차원: 200, 피드포워드 차원: 800
   - 8개 헤드 (공간: 4, 시간: 4)

6. **재구성 헤드**: 완전 연결 계층으로 마스크된 패치 복원

**사전 훈련 설정**:[1]

- **데이터셋**: Temple University Hospital EEG Corpus (TUEG) - 69,652개 임상 EEG 기록
- **전처리**:
  - 5분 미만 기록 제거
  - 첫 1분, 마지막 1분 삭제
  - 19개 표준 채널 선택 (10-20 국제 전극 배치)
  - 대역통과 필터: 0.3-75 Hz
  - 노치 필터: 60 Hz (전력선 잡음)
  - 200 Hz로 리샘플링, 30초 비중첩 샘플 분할
  - 절대값 100 μV 초과 데이터 제거

- **최종 훈련 데이터**: 1,109,545개 샘플 (약 9,000시간+)

- **훈련 하이퍼파라미터**:
  - 마스크 비율: 50%
  - 배치 크기: 128
  - 에포크: 40
  - 옵티마이저: AdamW (기본 설정)
  - 학습률: 5e-4, 가중치 감쇠: 5e-2
  - 학습률 스케줄: CosineAnnealingLR

***

### 4. 성능 향상 및 실험 결과

#### 4.1 다운스트림 작업 평가

CBraMod는 **10개 BCI 작업에서 12개 공개 데이터셋으로 평가**되었습니다:[1]

| BCI 작업 | 데이터셋 | 채널 수 | 샘플 수 |
|---------|---------|--------|--------|
| 감정 인식 | FACED (9-class) | 32 | 10,332 |
| | SEED-V (5-class) | 62 | 117,744 |
| 운동 상상 | PhysioNet-MI (4-class) | 64 | 9,837 |
| | SHU-MI (2-class) | 32 | 11,988 |
| 수면 분류 | ISRUC (5-class) | 6 | 89,240 |
| 발작 탐지 | CHB-MIT (2-class) | 16 | 326,993 |
| 상상 음성 | BCIC2020-3 (5-class) | 64 | 6,000 |
| 정신 장애 진단 | Mumtaz2016 (2-class) | 19 | 7,143 |
| 경각성 추정 | SEED-VIG | 17 | 20,355 |
| 정신 스트레스 | MentalArithmetic (2-class) | 20 | 1,707 |
| 사건 분류 | TUEV (6-class) | 16 | 112,491 |
| 비정상 탐지 | TUAB (2-class) | 16 | 409,455 |

#### 4.2 주요 성능 결과

**감정 인식 작업** (표 2):[1]

FACED (9-class) 데이터셋에서 CBraMod는 기존 최고 성능 모델인 LaBraM-Base와 비교하여:
- 코헨의 카파: 0.5041 → 0.5509 (**+8.5%**)
- 가중 F1: 0.5288 → 0.5618 (**+6.2%**)

SEED-V (5-class)에서:
- 코헨의 카파: 0.2386 → 0.2569 (**+7.7%**)
- 가중 F1: 0.3974 → 0.4101 (**+3.2%**)

**운동 상상 분류** (표 3):[1]

PhysioNet-MI (4-class)에서 LaBraM-Base 대비:
- 코헨의 카파: 0.4912 → 0.5222 (**+6.3%**)
- 가중 F1: 0.6177 → 0.6427 (**+4.1%**)

SHU-MI (2-class)에서 BIOT 대비:
- AUROC: 0.6609 → 0.6988 (**+5.7%**)
- AUC-PR: 0.6761 → 0.7139 (**+5.6%**)

#### 4.3 주의 메커니즘 비교

주의 메커니즘의 효과를 검증하기 위해 네 가지 설계를 비교했습니다:[1]

1. **완전 주의(Full Attention)**: 모든 EEG 패치 간 의존성을 함께 모델링 - **최악의 성능**
2. **축선 주의(Axial Attention)**: 특정 축선 차원을 순차적으로 모델링 - 중간 성능
3. **CCNet 기반 Criss-Cross**: 이미지를 위해 설계된 단일 맵 크로스 주의 - 약간 나은 성능
4. **CBraMod (Criss-Cross)**: **이중 병렬 공간-시간 주의** - **최고 성능**

이는 EEG의 이질적 의존성을 병렬로 모델링하는 것이 순차적 또는 완전 모델링보다 **우월함**을 증명합니다.[1]

#### 4.4 위치 인코딩 비교

세 가지 위치 인코딩 설계를 비교했습니다:[1]

1. **PE 없음(w/o PE)**: 최악의 성능
2. **절대 위치 인코딩(APE)**: 채널 번호 기반 고정 인코딩 - 중간 성능
3. **조건부 위치 인코딩(CPE)**: 동적 학습 - 나은 성능
4. **비대칭 조건부 위치 인코딩(ACPE)**: **비대칭 설계** - **최고 성능**

ACPE의 우월성은 EEG 신호의 **비대칭적 공간-시간 특성**을 더 잘 반영함을 시사합니다.[1]

#### 4.5 사전 훈련 영향 분석

세 가지 설정의 절제 연구:[1]

- **정제된 사전 훈련**: 최고 성능 (베이스라인)
- **오염된 사전 훈련**: 정제 없이 TUEG 사용 - 성능 **감소 4-6%**
- **사전 훈련 없음**: 다운스트림 데이터에서만 훈련 - 성능 **감소 2-4%**

이는 **데이터 품질과 사전 훈련이 모두 중요함**을 입증합니다.[1]

#### 4.6 저자원 환경 성능 (30% 데이터)

실제 적용 시나리오에서 레이블된 데이터가 부족한 경우:[1]

FACED에서 30% 데이터 사용 시:
- CBraMod: 0.3239 코헨의 카파 (전체 대비 64% 유지)
- BIOT: 0.2573 (vs 0.4476 전체)
- LaBraM: 0.2672

CBraMod는 **저자원 환경에서도 기존 모델을 능가**합니다.[1]

***

### 5. 모델의 일반화 성능 향상 가능성 중점 분석

#### 5.1 교차-피험자 일반화(Cross-Subject Generalization)

일반화 성능 향상의 핵심은 **구조적 특성 기반 설계**에 있습니다:[1]

**공간-시간 이질성 활용**:
- EEG는 이미지와 달리 **채널 간** 의존성과 **시간 간** 의존성이 근본적으로 다릅니다.
- Criss-Cross 트랜스포머가 이를 **별도로 모델링**하여 개인 간 EEG 특성 차이에 대한 강건성 향상

**비대칭 위치 인코딩**:
- ACPE는 **긴 범위 공간 정보**와 **단거리 시간 정보**를 구별하여 인코딩
- 다양한 참조 방식(귀, 평균, REST, 쌍극)을 가진 채널 구성에 **적응 가능**
- 이는 다양한 기관에서 수집된 데이터에 대한 일반화를 향상

**대규모 다양한 사전 훈련 데이터**:
- TUEG: 69,652개 임상 EEG 기록 (약 27,062시간)
- 40+ 다양한 채널 구성으로부터 학습
- 이전 기초 모델(LaBraM: 2,534.78시간) 대비 **3.5배 큰 데이터셋**[1]

#### 5.2 교차-작업 일반화(Cross-Task Generalization)

10개 서로 다른 BCI 작업에서의 우수한 성능은 **범용적 EEG 표현 학습**을 입증합니다:[1]

**패치 기반 마스크 재구성의 강점**:
- 자기 지도 학습으로 **작업 불특정 표현** 습득
- 감정 인식, 운동 상상, 수면 분류, 발작 탐지 등 다양한 신경 현상을 캡처

**다양한 신호 특성 처리**:
- 다양한 채널 수(6~64), 시간 길이(1~30초), 샘플링 레이트(160~1000 Hz)를 **통일된 패칭 전략**으로 처리
- 이는 **도메인 일반화 능력**을 강화

#### 5.3 최신 경향과의 비교

최근 2025년의 EEG 기초 모델 발전과 비교:[2][3][4]

| 특성 | CBraMod | ALFEE (2025) | LCM (2025) |
|-----|---------|------------|-----------|
| 구조 설계 | Criss-Cross 주의 | 하이브리드 주의 | 시간-스펙트럼 주의 |
| 위치 인코딩 | 비대칭 조건부 | 채널 적응형 | 표준 위치 |
| 사전 훈련 데이터 | ~9,000시간 | 보고 안 함 | 보고 안 함 |
| 평가 작업 수 | 10개 (12 데이터셋) | 포괄적 | 다중 벤치마크 |
| 교차 피험자 성능 | 높음 | 향상됨 | 매우 높음 |

**CBraMod의 고유한 강점**:
1. **가장 포괄적인 평가**: 10개 작업 × 12 데이터셋
2. **구조적 특성 기반 설계**: EEG의 이질적 특성을 명시적으로 활용
3. **검증된 대규모 데이터**: TUEG의 광범위한 임상 데이터

***

### 6. 모델의 한계

논문에서 명시적으로 인정하는 한계:[1]

**1. 고정 특징 추출기로 사용 불가**
- 테이블 18의 절제 연구에서, 사전 훈련된 가중치를 고정한 상태로 분류기만 조정하면 성능 **급격히 감소**
- CLIP(비전 모델)이나 SAM(세그멘테이션 모델) 같은 완전 기초 모델 수준 아직 미달
- 다운스트림 작업에 **세밀한 조정(fine-tuning)이 필수**

**2. 모델 크기 및 효율성**
- 논문에서 명시: "효율적이고 효과적인 EEG 기초 모델 개발 필요"[1]
- 대규모 모델로 인한 배포 및 실시간 BCI 적용의 제약

**3. 데이터 품질 의존성**
- 아블레이션 연구(표 4)에서 "더 크고 더 깨끗한 EEG 코퍼스 필수"[1]
- TUEG 데이터에도 여전히 오염(unmarked noise, artifacts)이 존재

**4. 모델 크기-성능 스케일링 법칙 미해명**
- 향후 작업으로 "더 큰 사전 훈련 데이터셋과 모델 크기 탐구" 명시[1]

**5. 실시간 처리의 한계**
- 블록 길이 증가 시 계산 복잡도 증가로 실시간 BCI 응용에 제약

***

### 7. 향후 연구에 미치는 영향 및 고려사항

#### 7.1 향후 연구에 미치는 영향

**1. EEG 기초 모델 설계 패러다임 변환**

CBraMod의 Criss-Cross 전략은 **EEG의 구조적 특성을 명시적으로 활용하는 새로운 패러다임**을 제시합니다: 향후 연구자들은 신호 모달리티(EEG, MEG, ECoG 등)의 **고유한 특성을 모델 아키텍처에 반영**하는 것이 중요함을 인식할 것입니다.[1]

**2. 위치 인코딩의 재평가**

절대 위치 인코딩(APE) 대신 **비대칭 조건부 위치 인코딩(ACPE)**의 우월성은 다양한 데이터 형식 적응 능력의 중요성을 강조합니다. 이는 의료 영상, 시계열 분석 등 다른 도메인의 기초 모델 개발에 **영감을 제공**할 것입니다.[1]

**3. 대규모 다중 작업 평가 표준 수립**

CBraMod의 10개 작업 × 12 데이터셋 평가는 **EEG 기초 모델 벤치마킹의 새로운 표준**입니다. 최근 NeurIPS 2025 EEG Foundation Challenge는 이러한 방향을 강화하고 있습니다. 향후 연구는 더욱 **포괄적인 교차-피험자, 교차-작업 평가**를 요구할 것입니다.[5]

**4. 자기 지도 학습 최적화**

패치 기반 마스크 재구성의 효과를 입증한 CBraMod는 **자기 지도 학습이 EEG 도메인에서 매우 효과적**임을 보여줍니다. 향후 연구는 더욱 정교한 자기 지도 목표(예: 시간 역학 예측, 스펙트럼-시간 일관성) 탐색으로 이어질 것입니다.[3][6]

**5. 신경과학적 해석가능성**

공간-시간 주의 메커니즘의 분리가 신경생물학적 타당성을 가질 가능성을 제시합니다. 향후 연구는 **학습된 표현이 뇌의 공간적 및 시간적 처리와 일치하는지** 검증할 수 있습니다.

#### 7.2 최신 연구 기반 향후 고려사항

최근 2024-2025년 EEG 기초 모델 발전 트렌드에 따른 고려사항:[7][4][8][2][3]

**1. 기하학적 제약의 통합 (ManifoldFormer, 2025)**[8]

신경 동역학이 저차원 리만 다양체 위에 제약된다는 신경과학적 통찰을 활용. CBraMod에 **리만 기하학적 제약**을 추가하면:
- 교차 피험자 일반화 **6-10% 개선 가능** (기존 EEG 기초 모델 대비)
- 신경생물학적 타당성 증대

**2. 다중 손실 함수 최적화**

ALFEE(2025)의 접근처럼 **시간-주파수 이중 재구성 + 작업 예측 + 시간 예측** 조합:[3]
- CBraMod의 단순 MSE 손실보다 더 풍부한 표현 학습 가능
- 다양한 EEG 현상에 대한 일반화 향상

**3. 동적 채널 적응 (ALFEE, 2025)**[3]

변수 채널 수를 처리하기 위한 **채널 인코더** 통합:
- CBraMod의 패치 기반 접근도 일부 적응성 제공하지만
- 더욱 명시적인 **채널 축소 메커니즘** 추가 시 효율성 향상

**4. 임상 적용 지향 설계**

최근 EEG Foundation Challenge(2025)에서 강조되는 **실제 임상 환경의 제약 반영**:[5]
- **음성 건강한 대조군뿐 아니라 신경정신과 장애 포함**
- 다양한 **신경생물학적 특성**을 가진 인구 집단에서의 일반화

**5. 연합 학습(Federated Learning)의 통합**[7]

개인정보 보호를 위한 연합 학습 적용:
- CBraMod의 모델 아키텍처는 **분산 훈련에 적합**
- 다양한 의료 기관의 EEG 데이터를 통합하여 더욱 강력한 일반화 달성

**6. 신경 형태 컴퓨팅(Neuromorphic Computing)**[7]

저전력 뇌-컴퓨터 인터페이스 구현:
- CBraMod의 트랜스포머 기반 구조를 신경 형태 칩(neuromorphic chips)에 매핑
- 실시간 BCI 응용의 **에너지 효율성 극대화**

**7. 대규모 모델 스케일링 법칙 탐구**

LCM(2025)처럼 더 큰 모델(예: 수억 파라미터) 훈련의 영향 분석:[4]
- CBraMod는 12개 트랜스포머 블록, 200차원, 8개 헤드
- 향후: 24-32개 블록, 512-1024차원으로 확장 시 성능 트렌드 분석

**8. 교차 모달리티 전이**[4]

비전 및 NLP 기초 모델의 지식 활용:
- **자기주의(Self-Attention)** 메커니즘을 이미지 모델(ViT)에서 차용한 CBraMod의 접근 확대
- EEG를 이미지로 변환(시간-주파수 스펙트로그램) 후 다중 모달 기초 모델로 결합

***

### 8. 결론

**CBraMod**는 EEG 기초 모델의 발전에 중추적인 기여를 하는 연구입니다. **Criss-Cross 트랜스포머**와 **비대칭 조건부 위치 인코딩**이라는 혁신적 설계를 통해 EEG 신호의 고유한 공간-시간 이질성을 명시적으로 모델링하며, 10개 BCI 작업에서 최고 성능을 달성했습니다.[1]

**일반화 성능의 핵심 강점**:
- 대규모 임상 데이터(~9,000시간)를 활용한 강력한 사전 훈련
- 다양한 채널 구성 및 신호 형식에 대한 적응성
- 저자원 환경(30% 데이터)에서도 우수한 성능 유지

**향후 개선 방향**:
- 더 크고 깨끗한 EEG 데이터셋 수집
- 기하학적 제약(리만 다양체) 통합
- 효율적이고 실시간 처리 가능한 경량 모델 개발
- 다중 손실 함수 및 동적 채널 적응 메커니즘 추가

CBraMod의 설계 철학은 **도메인 특화 기초 모델 개발**의 새로운 방향을 제시하며, EEG 기반 신경과학 연구 및 BCI 기술의 실용화를 가속할 것으로 기대됩니다.

***

### 참고 문헌

[1](https://ppl-ai-file-upload.s3.amazonaws.com/web/direct-files/attachments/65988149/02ae6da2-9114-4c81-91ba-fd903dd42e32/2412.07236v6.pdf)
[2](https://ieeexplore.ieee.org/document/11204282/)
[3](https://arxiv.org/abs/2505.06291)
[4](https://arxiv.org/abs/2502.17464)
[5](https://www.themoonlight.io/ko/review/eeg-foundation-challenge-from-cross-task-to-cross-subject-eeg-decoding)
[6](https://arxiv.org/pdf/2503.10362.pdf)
[7](https://ieeexplore.ieee.org/document/11145817/)
[8](https://www.semanticscholar.org/paper/5d46587dd2ec71cf9e604c47d4922128fcbbbf98)
[9](https://www.frontiersin.org/articles/10.3389/fbioe.2024.1448903/full)
[10](https://www.mdpi.com/2076-3425/15/8/805)
[11](https://www.semanticscholar.org/paper/b7d0a857bb2e97fd3c851b4ff0809bfa055312e8)
[12](https://iopscience.iop.org/article/10.1088/1741-2552/add08f)
[13](https://translational-medicine.biomedcentral.com/articles/10.1186/s12967-025-06862-z)
[14](https://arxiv.org/html/2412.07236)
[15](https://arxiv.org/pdf/2401.10278.pdf)
[16](http://arxiv.org/pdf/2502.17464.pdf)
[17](http://arxiv.org/pdf/2310.18689.pdf)
[18](https://arxiv.org/html/2409.12454v1)
[19](https://arxiv.org/pdf/2311.03764.pdf)
[20](https://arxiv.org/pdf/2410.19779.pdf)
[21](https://arxiv.org/html/2506.19141v1)
[22](https://arxiv.org/abs/2406.17086)
[23](https://pubmed.ncbi.nlm.nih.gov/38865781)
[24](https://www.brainaccess.ai/eeg-foundation-models-unlocking-the-next-generation-of-neurotechnology/)
[25](https://www.sciencedirect.com/science/article/abs/pii/S0020025524014907)
[26](https://arxiv.org/abs/2511.15218)
[27](https://dl.acm.org/doi/10.1145/3503161.3548243)
[28](https://www.sciencedirect.com/science/article/pii/S001048252400790X)
[29](https://www.sciencedirect.com/science/article/abs/pii/S1474034624006220)
[30](https://velog.io/@kbm970709/%EB%85%BC%EB%AC%B8-%EB%A6%AC%EB%B7%B0-TI-MAE-Self-Supervised-Masked-Time-Series-Autoencoders)
